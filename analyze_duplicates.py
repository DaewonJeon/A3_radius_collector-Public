"""
ì¤‘ë³µ ë¶„ì„ ë° ì§„ì •í•œ êµì°¨ ë§¤ì¹­ í¸ì˜ì  ì¶”ì¶œ ìŠ¤í¬ë¦½íŠ¸
"""
import pandas as pd
import re

def normalize_name(name):
    """ì´ë¦„ ì •ê·œí™”"""
    if pd.isna(name):
        return ''
    name = str(name).strip().lower()
    name = name.replace(' ', '').replace('-', '').replace('_', '')
    return name

def normalize_address(address):
    """ì£¼ì†Œ ì •ê·œí™” - ë„ë¡œëª… + ë²ˆí˜¸ë§Œ ì¶”ì¶œ"""
    if pd.isna(address) or not address:
        return ''
    address = str(address).strip()
    address = address.replace("ì„œìš¸íŠ¹ë³„ì‹œ", "ì„œìš¸").replace("ì„œìš¸ì‹œ", "ì„œìš¸")
    
    road_pattern = r'([ê°€-í£]+(?:ë¡œ|ê¸¸|ëŒ€ë¡œ)[0-9ê°€-í£]*)\s*(\d+(?:-\d+)?)'
    match = re.search(road_pattern, address)
    
    if match:
        road_name = match.group(1)
        road_num = match.group(2)
        gu_pattern = r'(ì˜ë“±í¬êµ¬)'
        gu_match = re.search(gu_pattern, address)
        gu = gu_match.group(1) if gu_match else ""
        normalized = f"ì„œìš¸ {gu} {road_name} {road_num}".strip()
        return " ".join(normalized.split())
    return address

# CSV íŒŒì¼ ë¡œë“œ
df = pd.read_csv('matched_stores.csv', encoding='utf-8-sig')

print('=' * 70)
print('ğŸ“Š ê¸°ë³¸ ì •ë³´')
print('=' * 70)
print(f'ì´ í–‰ ìˆ˜: {len(df)}')
print(f'\nì¶œì²˜ë³„ ê°œìˆ˜:')
print(df['ì¶œì²˜'].value_counts())

print('\n' + '=' * 70)
print('ğŸ“Š ë§¤ì¹­ì´ìœ ë³„ ê°œìˆ˜')
print('=' * 70)
for reason, count in df['ë§¤ì¹­ì´ìœ '].value_counts().items():
    print(f'  {reason}: {count}ê°œ')

# ì •ê·œí™”ëœ ì´ë¦„/ì£¼ì†Œ ì»¬ëŸ¼ ì¶”ê°€
df['ì´ë¦„_ì •ê·œí™”'] = df['ì´ë¦„'].apply(normalize_name)

# ì£¼ì†Œ_ì •ê·œí™” ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ í™•ì¸ (ì´ë¯¸ ìˆìŒ)
print('\n' + '=' * 70)
print('ğŸ“Š ì¤‘ë³µ ë¶„ì„')
print('=' * 70)
dup_addr = df[df.duplicated(subset=['ì£¼ì†Œ_ì •ê·œí™”'], keep=False)]
print(f'ì£¼ì†Œ_ì •ê·œí™” ê¸°ì¤€ ì¤‘ë³µ í–‰: {len(dup_addr)}')

dup_name = df[df.duplicated(subset=['ì´ë¦„_ì •ê·œí™”'], keep=False)]
print(f'ì´ë¦„_ì •ê·œí™” ê¸°ì¤€ ì¤‘ë³µ í–‰: {len(dup_name)}')

# 2ì°¨ê²€ì¦ìœ¼ë¡œë§Œ ë§¤ì¹­ëœ í¸ì˜ì 
print('\n' + '=' * 70)
print('ğŸ” 2ì°¨ê²€ì¦ìœ¼ë¡œë§Œ ë§¤ì¹­ëœ í¸ì˜ì ')
print('=' * 70)
secondary = df[df['ë§¤ì¹­ì´ìœ '] == '2ì°¨ê²€ì¦']
print(f'ì´ {len(secondary)}ê°œ:')
for _, row in secondary.iterrows():
    print(f"  - {row['ì´ë¦„']}")
    print(f"    ì¶œì²˜: {row['ì¶œì²˜']}")
    print(f"    ì£¼ì†Œ: {row['ì£¼ì†Œ']}")
    print()

# ì¤‘ë³µ ì œê±° í›„ ê³ ìœ  í¸ì˜ì  ì¶”ì¶œ
print('\n' + '=' * 70)
print('ğŸ¯ ì¤‘ë³µ ì œê±° (ì£¼ì†Œ_ì •ê·œí™” ê¸°ì¤€ìœ¼ë¡œ ì²« ë²ˆì§¸ë§Œ ìœ ì§€)')
print('=' * 70)
df_unique = df.drop_duplicates(subset=['ì£¼ì†Œ_ì •ê·œí™”'], keep='first')
print(f'ì¤‘ë³µ ì œê±° í›„ ê³ ìœ  í¸ì˜ì : {len(df_unique)}ê°œ')

# ê²°ê³¼ ì €ì¥
df_unique.to_csv('matched_stores_unique.csv', index=False, encoding='utf-8-sig')
print(f'ì €ì¥ ì™„ë£Œ: matched_stores_unique.csv')

# ì¶œì²˜ë³„ ë¶„í¬
print('\nì¶œì²˜ë³„ ë¶„í¬ (ì¤‘ë³µ ì œê±° í›„):')
print(df_unique['ì¶œì²˜'].value_counts())
